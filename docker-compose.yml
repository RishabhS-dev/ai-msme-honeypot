version: '3.8'

services:
  # Elasticsearch for log storage and analysis
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: honeypot-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - honeypot-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Kibana for visualization (optional, for advanced users)
  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    container_name: honeypot-kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - xpack.security.enabled=false
    ports:
      - "5601:5601"
    networks:
      - honeypot-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped

  # Redis for caching and session management
  redis:
    image: redis:7-alpine
    container_name: honeypot-redis
    ports:
      - "6379:6379"
    networks:
      - honeypot-network
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data

  # SSH Honeypot (Cowrie)
  ssh-honeypot:
    image: cowrie/cowrie:latest
    container_name: honeypot-ssh
    ports:
      - "2222:2222"  # SSH honeypot port
    volumes:
      - ./honeypots/ssh-honeypot/etc:/cowrie/cowrie-git/etc
      - ./honeypots/ssh-honeypot/var:/cowrie/cowrie-git/var
      - ssh_logs:/cowrie/cowrie-git/var/log/cowrie
    networks:
      - honeypot-network
    restart: unless-stopped
    environment:
      - COWRIE_HOSTNAME=web-server-01
      - COWRIE_SSH_PORT=2222
    depends_on:
      - elasticsearch

  # Web Honeypot (Custom)
  web-honeypot:
    build:
      context: ./honeypots/web-honeypot
      dockerfile: Dockerfile
    container_name: honeypot-web
    ports:
      - "8080:80"   # HTTP honeypot
      - "8443:443"  # HTTPS honeypot
    volumes:
      - web_logs:/var/log/honeypot
    networks:
      - honeypot-network
    restart: unless-stopped
    environment:
      - LOG_LEVEL=INFO
      - ELASTICSEARCH_HOST=elasticsearch:9200
    depends_on:
      - elasticsearch

  # FTP Honeypot
  ftp-honeypot:
    build:
      context: ./honeypots/ftp-honeypot
      dockerfile: Dockerfile
    container_name: honeypot-ftp
    ports:
      - "2121:21"   # FTP honeypot port
    volumes:
      - ftp_logs:/var/log/honeypot
    networks:
      - honeypot-network
    restart: unless-stopped
    environment:
      - FTP_USER=anonymous
      - FTP_PASS=guest
      - LOG_ELASTICSEARCH=true
      - ELASTICSEARCH_HOST=elasticsearch:9200
    depends_on:
      - elasticsearch

  # SMB Honeypot (Dionaea)
  smb-honeypot:
    image: dinotools/dionaea:latest
    container_name: honeypot-smb
    ports:
      - "445:445"   # SMB port
      - "135:135"   # RPC port
    volumes:
      - smb_logs:/opt/dionaea/var/log
      - ./honeypots/smb-honeypot/etc:/opt/dionaea/etc/dionaea
    networks:
      - honeypot-network
    restart: unless-stopped
    depends_on:
      - elasticsearch

  # Main Backend API Server
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: honeypot-backend
    ports:
      - "5000:5000"
    volumes:
      - ./backend:/app
      - /var/run/docker.sock:/var/run/docker.sock  # For dynamic container management
    networks:
      - honeypot-network
    environment:
      - NODE_ENV=production
      - PORT=5000
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - REDIS_URL=redis://redis:6379
      - FRONTEND_URL=http://localhost:3000
      - EMAIL_USER=${EMAIL_USER}
      - EMAIL_PASS=${EMAIL_PASS}
      - TWILIO_SID=${TWILIO_SID}
      - TWILIO_TOKEN=${TWILIO_TOKEN}
      - TWILIO_FROM=${TWILIO_FROM}
    depends_on:
      elasticsearch:
        condition: service_healthy
      redis:
        condition: service_started
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Frontend React Application
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: honeypot-frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend/src:/app/src
    networks:
      - honeypot-network
    environment:
      - REACT_APP_API_BASE_URL=http://localhost:5000
      - REACT_APP_WS_URL=ws://localhost:5000
    depends_on:
      - backend
    restart: unless-stopped

  # Log Shipper (Filebeat) - Sends logs to Elasticsearch
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.8.0
    container_name: honeypot-filebeat
    user: root
    volumes:
      - ./config/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - ssh_logs:/var/log/cowrie:ro
      - web_logs:/var/log/web-honeypot:ro
      - ftp_logs:/var/log/ftp-honeypot:ro
      - smb_logs:/var/log/smb-honeypot:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - honeypot-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped
    command: filebeat -e -strict.perms=false

  # AI Processing Service (Python)
  ai-processor:
    build:
      context: ./backend/ai-engine
      dockerfile: Dockerfile
    container_name: honeypot-ai
    volumes:
      - ./backend/ai-engine:/app
      - ai_models:/app/models
    networks:
      - honeypot-network
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - REDIS_URL=redis://redis:6379
      - MODEL_PATH=/app/models
      - LOG_LEVEL=INFO
    depends_on:
      - elasticsearch
      - redis
    restart: unless-stopped
    command: python -u processor.py

  # Nginx Reverse Proxy and Load Balancer
  nginx:
    image: nginx:alpine
    container_name: honeypot-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/ssl:/etc/nginx/ssl:ro
    networks:
      - honeypot-network
    depends_on:
      - frontend
      - backend
    restart: unless-stopped

  # Network Traffic Monitor
  traffic-monitor:
    build:
      context: ./honeypots/traffic-monitor
      dockerfile: Dockerfile
    container_name: honeypot-traffic
    network_mode: host
    privileged: true
    volumes:
      - ./honeypots/traffic-monitor:/app
    environment:
      - ELASTICSEARCH_HOST=localhost:9200
      - INTERFACE=eth0
      - LOG_LEVEL=INFO
    depends_on:
      - elasticsearch
    restart: unless-stopped

volumes:
  elasticsearch_data:
    driver: local
  redis_data:
    driver: local
  ssh_logs:
    driver: local
  web_logs:
    driver: local
  ftp_logs:
    driver: local
  smb_logs:
    driver: local
  ai_models:
    driver: local

networks:
  honeypot-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# Health Check Script
x-healthcheck-config: &healthcheck-config
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 60s